import os
from dotenv import load_dotenv
from crewai import Agent, Task, Crew, Process, LLM
from tools import analyze_emotional_timeline

# Load environment variables from the .env file
load_dotenv()

API_KEY = os.getenv("GROQ_API_KEY")

if API_KEY is None:
    print("Warning: No GROQ_API_KEY found in environment. Please set one in .env")
    
# Initialixing LLM
llm = LLM(
    model="groq/llama-3.1-8b-instant",
    api_key=API_KEY
)

# Agent Definitions
emotional_analyst = Agent(
    role="Emotional Analyst",
    backstory="A careful analyst who reads emotional cues from text.",
    goal="Map the conversation and flag any points of emotional escalation.",
    tools=[analyze_emotional_timeline],
    llm=llm,
    verbose=True
)

perspective_balancer = Agent(
    role="Perspective Balancer",
    backstory="A neutral mediator who helps users see the other side.",
    goal="Explain what the other person (not the user) is likely feeling to encourage empathy.",
    llm=llm,
    verbose=True
)

boundary_guardian = Agent(
    role="Boundary Guardian",
    backstory="An assertive coach focused on protecting user boundaries.",
    goal="Recommend response strategies that protect the user from verbal abuse or boundary violations. NEVER suggest manipulative tactics.",
    llm=llm,
    verbose=True
)

de_escalation_coach = Agent(
    role="De-escalation Coach",
    backstory="A synthesizer that pulls together analysis into actionable advice.",
    goal="Synthesize the earlier analysis and craft a final set of response options.",
    llm=llm,
    verbose=True
)

#Task Definitions
emotion_task = Task(
    description=(
        "Analyze the following conversation using the 'Analyze Emotional Timeline' tool: \n\n"
        "'{conversation}'\n\n"
        "Output a brief summary of who said what and flag specific messages where emotions escalated."
    ),
    expected_output="An emotional timeline summary and a list of specific escalation points.",
    agent=emotional_analyst
)

perspective_task = Task(
    description=(
        "Review the emotional timeline generated by the Emotional Analyst. "
        "Write a short paragraph explaining what the 'Other' person is likely feeling and why they might be reacting this way."
    ),
    expected_output="A perspective analysis explaining the other person's underlying feelings.",
    agent=perspective_balancer
)

synthesis_task = Task(
    description=(
        "Review all previous analysis. Produce a final report containing EXACTLY the following sections:\n"
        "1. Emotional Summary\n"
        "2. Escalation Points\n"
        "3. Suggested Responses (Option 1: De-escalation, Option 2: Boundary-respecting, Option 3: Empathy-forward)\n"
        "4. Ethical Disclaimer ('This is an AI analysis. Human judgment is required before sending.')"
    ),
    expected_output="A highly structured final report with exactly 3 distinct response options and the ethical disclaimer.",
    agent=de_escalation_coach,
    context=[emotion_task, perspective_task] # Forces the coach to wait for and read the previous outputs
)

#Crew Orchestration Export
def create_crew() -> Crew:
    return Crew(
        agents=[emotional_analyst, perspective_balancer, boundary_guardian, de_escalation_coach],
        tasks=[emotion_task, perspective_task, synthesis_task],
        process=Process.sequential,
        verbose=True
    )